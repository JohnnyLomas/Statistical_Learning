---
title: "STAT760_Homework2"
author: "Natalie Bladis, Johnny Lomas"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r include=FALSE}
#setwd("/Users/ntb3/Documents/STAT_760_Statistical_Learning/Statistical_Learning")
setwd("/Users/jslomas/Box/STAT_760/Statistical_Learning")
```
## Exercise 1. (ESL Ex. 3.12) – 3 pts
Show that the ridge regression estimates can be obtained by ordinary least squares regression
on an augmented data set. We augment the centered matrix X with p additional rows $\sqrt{\lambda{I}}$, and
augment y with p zeros. By introducing artificial data having response value zero, the fitting
procedure is forced to shrink the coefficients toward zero. This is related to the idea of hints due to
Abu-Mostafa (1995), where model constraints are implemented by adding artificial data examples
that satisfy them.

## Solution:
Let $X^*=\begin{bmatrix}X \\\sqrt{\lambda}I_p\end{bmatrix}$ and $y^* = \begin{bmatrix}y \\0_p\end{bmatrix}$ where $I_p$ is a $p \times p$ identify matrix and $0_p$ is a $p \times 1$ vector of zeros. 

Then 

$$
\begin{aligned}
X^{*T}X^* &= \begin{bmatrix}X \sqrt{\lambda}I_p\end{bmatrix} \begin{bmatrix}X \\\sqrt{\lambda}I_p\end{bmatrix} \\
&= X^TX+\lambda I_p
\end{aligned}
$$
and 
$$
\begin{aligned}
X^{*T}y^* &= \begin{bmatrix}X \sqrt{\lambda}I_p\end{bmatrix} \begin{bmatrix} y \\0_p\end{bmatrix} \\
&= X^Ty+ \sqrt\lambda I_p 0_p \\
&= X^Ty
\end{aligned}
$$
Therefore, 
$$
\begin{aligned}
\hat{\beta}_{new} &= (X^{*T}X^*)^{-1}X^{*T}y^* \\
&= (X^Ty+ \lambda I_p)^{-1} X^Ty
\end{aligned}
$$
Which is the $\hat{\beta}$ estiamte for ridge regression. 

## Exercise 2. (Programming) – 12 pts
Use prostate cancer example to reproduce the following figure. The Prostate data are available
from the book website https://www.hastie.su.domains/ElemStatLearn/.


```{r}
setwd("/Users/jslomas/Box/STAT_760/Statistical_Learning/HW2")
library(dplyr)
library(ggplot2)

# Input (x): Augmented data matrix
# Input (y): Response vector
# Return: Fitted parameter vector (beta)
fitLeastSquares <- function(x, y){
   beta = solve(t(x) %*% x) %*% t(x) %*% y
   return(beta)
}

predictLeastSquares <- function(x, beta) {
  y_hat <- x %*% beta
  return(y_hat)
}

# Input (y)    : Original response vector
# Input (y_hat): Predicted response vector
# Return       : RSS value, scalar
computeRSS <- function(y, y_hat){
  rss <- t(y-y_hat) %*% (y-y_hat)
  return(rss)
}

prostate <- read.delim("prostate.tsv")
response <- as.matrix(prostate %>% select(lpsa))
data <- prostate %>% select(lcavol:pgg45)

plot_data <- data.frame()
# TODO: fit null case and add to plotting dataframe
null_rss <- sum((response - mean(response))^2)
plot_data <- rbind(plot_data, c(null_rss, 0))

for (feat in 1:ncol(data)){
  sets <- combn(1:ncol(data), feat)
  for (set in 1:ncol(sets)){
    data_subset <- data %>% select(sets[,set])
    data_subset <- cbind(rep(1, nrow(data)), data_subset)
    data_subset <- as.matrix(data_subset)
    
    beta_hat <- fitLeastSquares(data_subset, response)
    y_hat <- predictLeastSquares(data_subset, beta_hat)
    rss <- computeRSS(response, y_hat)
    
    plot_data <- rbind(plot_data, c(rss, feat))
  }
}

colnames(plot_data) <- c("RSS", "K")

ggplot(plot_data, aes(x=K, y=RSS)) +
  geom_point() +
  ylim(c(0,130)) +
  ylab("Residual Sum-of-Squares") +
  xlab("Subset size k")

```


1) Create a loop that creates a linear model for all possible subsets of size k for k = 0,1,2,....n=8 and computes rss for model and stores (k, RSS, model) #is model necessary??

2) for each value of K identify minimal RSS

3) Plot all data from one as grey, plot all data for 2 as red, connect all red points. 

4) Axes labels x= Subset Size k, y= Residual Sum-of-Squares, Title = none

## Exercise 3. (Programming) – 15 pts
Use prostate cancer example to produce a similar figure below (also Figure 3.7 in ESL), where
the x-axis is the parameter λinstead of degrees of freedom. The estimates of prediction errors
are obtained by 10-fold cross-validation. The Prostate data are available from the book website
https://www.hastie.su.domains/ElemStatLearn/.
1
